<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>音声入力デモ</title>
</head>

<body>
    <h1>音声入力デモ（Web Speech API）</h1>
    <button id="startBtn">:microphone: 音声入力開始</button>
    <button id="stopBtn">⏹ 停止</button>
    <p>認識結果: <span id="result"></span></p>
    <p id="message"></p>
    <p>無音経過: <span id="silenceTimer">0</span> ms</p>

    <script>
        const startBtn = document.getElementById("startBtn");
        const stopBtn = document.getElementById("stopBtn");

        let recognition;
        let running = false;
        let silenceStart = Date.now();
        let finalTranscript = "";
        let lastInterim = "";

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (!SpeechRecognition) alert("ブラウザ非対応");

        const startRecognition = async () => {
            if (running) return;
            running = true;

            recognition = new SpeechRecognition();
            recognition.lang = "ja-JP";
            recognition.continuous = true;
            recognition.interimResults = true;

            recognition.onresult = (e) => {
                let interimTranscript = "";
                for (let i = e.resultIndex; i < e.results.length; i++) {
                    const text = e.results[i][0].transcript;
                    if (e.results[i].isFinal) finalTranscript += text;
                    else interimTranscript += text;
                }
                document.getElementById("result").textContent = finalTranscript + interimTranscript;
                lastInterim = interimTranscript;
            };

            recognition.onerror = (e) => console.error(e);

            recognition.onend = () => {
                if (running) {
                    // ブラウザ側の自動停止時のみ再開
                    recognition.start();
                }
            };

            recognition.start();

            // --- 無音判定 ---
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            const audioCtx = new AudioContext();
            const source = audioCtx.createMediaStreamSource(stream);
            const analyser = audioCtx.createAnalyser();
            source.connect(analyser);
            analyser.fftSize = 2048;
            const dataArray = new Uint8Array(analyser.fftSize);

            const checkSilence = () => {
                analyser.getByteTimeDomainData(dataArray);
                const volume = dataArray.reduce((a, v) => a + Math.abs(v - 128), 0) / dataArray.length;

                const elapsed = Date.now() - silenceStart;
                document.getElementById("silenceTimer").textContent = elapsed;

                if (volume < 5) {
                    if (elapsed > 5000) { // 5秒無音で停止
                        running = false;
                        recognition.stop();
                        document.getElementById("message").innerHTML = "無音で停止しました";
                        return; // 無音停止時は再開させない
                    }
                } else {
                    silenceStart = Date.now();
                }
                if (running) requestAnimationFrame(checkSilence);
            };
            checkSilence();
        };

        startBtn.addEventListener("click", startRecognition);

        // 停止ボタン
        stopBtn.addEventListener("click", () => {
            running = false;
            if (recognition) recognition.stop();
            document.getElementById("message").innerHTML = "手動停止しました";
        });
    </script>

</body>

</html>